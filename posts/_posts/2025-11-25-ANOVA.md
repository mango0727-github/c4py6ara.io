---
layout: post
title: ANalysis Of VAriance
description: >
  This post is to introduce one of powerful statistical methods, ANOVA. 
sitemap: false
math: true
hide_last_modified: true
---
# ANalysis Of VAriance

## Overview

Estimation and hypothesis testing have been the main pillars in statistical inference in that they provide solid statistical reasoning based on samples collected from populations of interest. Over decades, various testing methodologies have been invented by renowned data scientists and engineers. Among the methodologies, a t-test is a simple but powerful tool in cases where the population is assumed to be normally distributed and the variance is unknown. In practice, thanks to the central limit theorem, the t-test is also quite robust and widely used even when the normality assumption is only approximately satisfied. However, the t-test is essentially designed for comparing one or two population means. When we want to compare more than two populations while controlling the overall Type I error, we use analysis of variance (ANOVA).

### T-Test

About t-test briefly, the idea is simple. t-test is used to compare the means of two populations (or groups) when the population variances are unknown.

Yeah, under this setting, there are two common cases: one where we assume equal variances (homoscedasticity) across populations, and one where we do not (think of Welchâ€™s t-test). However, we will not go into these details here, since our focus is ANOVA.

We utilize T-statistic as a test statistic for the T-test. T-statistic is defined as:

$$
T = \frac{ \bar{X} - \mu_0 }{ s / \sqrt{n} }
$$

## ANOVA

On the other hand, ANOVA is typically used when we want to compare three or more population means at the same time, although it can also be applied to two groups. > Fun fact: when ANOVA is applied to only two groups, it gives exactly the same result as the t-test (because $F = t^2$). We can put like this (hopefully not too simple): very roughly speaking, if the variance between groups is large compared to the variance within groups, then the populations are likely to have different means. 


### F-Distribution

Before we go deep into ANOVA, we should know F-distribution. **The F-distribution is the distribution of a ratio of two scaled chi-square random variables. More specifically, if $V_1 \sim \chi^2_{d_1}$ and $V_2 \sim \chi^2_{d_2}$ are independent, then

$$ F = \frac{
\displaystyle V_1 / d_1
}{
\displaystyle V_2 / d_2
} $$

follows an F-distribution with $d_1$ and $d_2$ degrees of freedom. Here, $V_1$ and $V_2$ are statistics that follow the chi-square distribution with $d_1$ and $d_2$ degrees of freedom, respectively. $V_1$ and $V_2$ are assumed to be independent with each other. There are many notable properties associated with F-distribution, however we narrow down to a property which is the relationship between an F-statistic and the chi-square distribution. Since a random variable (RV) following the chi-square distribution is the sum of independent standard normal random variables, the F-statistic above can be written as:

$$ F
= \frac{V_1/d_1}{V_2/d_2}
= \frac{ \dfrac{1}{d_1}\displaystyle\sum_{i=1}^{d_1}\dfrac{X_i^2}{\sigma_x^2} }{ \dfrac{1}{d_2}\displaystyle\sum_{i=1}^{d_2}\dfrac{Y_i^2}{\sigma_y^2} } $$

where $X_i \sim N(0, \sigma_x^2)$ for $i=1, ..., d_1$ and $Y_i \sim N(0, \sigma_y^2)$ for $i=1, ..., d_2$, respectively. It is noteworthy that the standardized and squared random variables -- $X_i^2 / \sigma_x^2$ and $Y_i^2 / \sigma_y^2$ -- each follow a chi-squared distribution with 1 degree of freedom. Therefore, 

$$ V_1 = \sum_{i=1}^{d_1} \frac{X_i^2}{\sigma_x^2} \sim \chi^2_{d_1}, \qquad V_2 = \sum_{i=1}^{d_2} \frac{Y_i^2}{\sigma_y^2} \sim \chi^2_{d_2} $$

### Estimation and testing 

All in all, the estimation and testing are based on samples collected from the populations. And what exactly do we want to do with ANOVA? We are trying to test whether all population means are equal or at least one of them is different. We assume that each population is normally distributed with a common variance. Recall the definition of F-distribution: It is a ratio of two random variables that independently follow the chi-square distribution with respective degrees of freedom, while each term acts as an estimator of the common variance $\sigma^2$ under the null hypothesis, because we divide the sums of squares by their respective degrees of freedom. Therefore, we can make use of F-distribution! But, someone can say, "didn't you say that ANOVA is used for groups more than three? How could that be possible! F-distribution is a ratio of two groups' variances. Your point doesn't make sense!" That's great question. To answer this, let's circle back to the purpose of ANOVA: to test whether all population means are equal or at least one of them is different. Just sit on it and ponder. In one-way ANOVA, we decompose the total variability into two sources: between-group variability and within-group variability. The F-statistic is the ratio of the mean square between groups to the mean square within groups. In other words, even though there may be many groups, the F-statistic itself is still a ratio of two quantities: the between-group variance estimate and the within-group variance estimate. Yeah! That's the intuition to use F-distribution in ANOVA.
Under this model, the F-statistic is defined as:

$$ F = \frac{\text{mean of squared deviations between groups}}{\text{mean of squared deviations within groups}} = \frac{
  \dfrac{1}{k-1}\displaystyle\sum_{i=1}^k n_i \left(\bar x_i - \bar x_{\cdot\cdot}\right)^2
}{
  \dfrac{1}{N-k}\displaystyle\sum_{i=1}^k \sum_{j=1}^{n_i} \left(x_{ij} - \bar x_i\right)^2
} $$

where \(k - 1\) is the degree-of-freedom for between-group variance, and $N - k$ is the degree-of-freedom for within-group variance. $N$ is the number of samples, and $k$ is the number of groups. The F-statistic follows an F-distribution under the null hypothesis.
